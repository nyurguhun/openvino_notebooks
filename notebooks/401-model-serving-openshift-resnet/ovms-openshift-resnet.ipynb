{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "121a89e4",
   "metadata": {},
   "source": [
    "# Deploy Image Classification with OpenVINO Model Server in OpenShift \n",
    "\n",
    "We will show you how to deploy OpenVINO Model Server (OVMS) in an OpenShift cluster and how to run a gRPC prediction request to the AI inference service.\n",
    "\n",
    "Requirements:\n",
    "- OpenShift cluster with the API access to a project\n",
    "- Installed [OpenVINO Model Server Operator](https://catalog.redhat.com/software/operators/search?q=openvino)\n",
    "- JupyterLab environment with Python3 deployed in the cluster\n",
    "\n",
    "If you don't have an OpenShift account, you can sign up for 30 or 60 day [free trial of Red Hat OpenShift](https://www.openshift.com/try)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157eb619",
   "metadata": {},
   "source": [
    "## Login to OpenShift with API Token\n",
    "\n",
    "First, let's login to OpenShift cluster using `oc` tool. \n",
    "\n",
    "In the Red Hat OpenShift console, click on your username and select `Copy login command`.\n",
    "\n",
    "![copy-login.png](notebook-files/copy-login.png)\n",
    "\n",
    "Click on `Display Token` and your API token will appear.\n",
    "\n",
    "![log-in-with-token.png](notebook-files/log-in-with-token.png)\n",
    "\n",
    "Copy `Log in with token` command and paste it in the cell below. The command has your `<user-API-token>` and `<cluster-DNS-name>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6014186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!oc login --token=<user-API-token> --server=https://api.<cluster-DNS-name>:6443"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf396e34",
   "metadata": {},
   "source": [
    "Create `ovms` project and go to this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c27a13a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (AlreadyExists): project.project.openshift.io \"ovms\" already exists\n",
      "Already on project \"ovms\" on server \"https://api.openvino5.3q12.p1.openshiftapps.com:6443\".\n"
     ]
    }
   ],
   "source": [
    "!oc new-project ovms\n",
    "!oc project ovms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c8e39a",
   "metadata": {},
   "source": [
    "## Create MinIO Storage\n",
    "\n",
    "OpenVINO Model Server exposes DL models over gRPC and REST interface. The models can be stored in cloud storage like AWS S3, Google Storage or Azure Blobs. In OpenShift and Kubernetes, Persistent Storage Claim could be used as well. In this tutorial, we will use MinIO service which is an equivalent of AWS S3.\n",
    "\n",
    "Let's create a MinIO service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e134a9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/minio created\n",
      "service/minio-service created\n"
     ]
    }
   ],
   "source": [
    "!oc apply -f minio.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cae5286",
   "metadata": {},
   "source": [
    "Next step is to download `mc`, MinIO Client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2571831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-12 16:12:42--  https://dl.min.io/client/mc/release/linux-amd64/mc\n",
      "Resolving dl.min.io (dl.min.io)... 178.128.69.202\n",
      "Connecting to dl.min.io (dl.min.io)|178.128.69.202|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20819968 (20M) [application/octet-stream]\n",
      "Saving to: ‘mc’\n",
      "\n",
      "mc                  100%[===================>]  19.86M  14.4MB/s    in 1.4s    \n",
      "\n",
      "2021-05-12 16:12:43 (14.4 MB/s) - ‘mc’ saved [20819968/20819968]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://dl.min.io/client/mc/release/linux-amd64/mc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3114e1e",
   "metadata": {},
   "source": [
    "Change the access permissions on `mc`, so we can run commands with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5493222",
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod 755 mc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5120c3f",
   "metadata": {},
   "source": [
    "Let's make an alias for the MinIO service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7e9e66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31;3;1mmc: <ERROR> \u001b[0m\u001b[31;3;1mUnable to initialize new alias from the provided credentials. Get \"http://minio-service.ovms:9000/probe-bucket-sign-sqrnwzcxz32r/?location=\": dial tcp 172.30.210.1:9000: connect: connection refused.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!./mc alias set minio http://minio-service.ovms:9000 minio minio123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b26fd8",
   "metadata": {},
   "source": [
    "Create a `minio/models` bucket; it's where we will store our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84813832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m\u001b[32;1mBucket created successfully `minio/models`.\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!./mc mb minio/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd48f16",
   "metadata": {},
   "source": [
    "## Create ResNet Model Repository\n",
    "\n",
    "Now, we will upload the model for serving in the OpenVINO Model Server. We will use [ResNet50 model in ONNX format](https://github.com/onnx/models/tree/master/vision/classification/resnet).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d4459e",
   "metadata": {},
   "source": [
    "Copy the ResNet model from its repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b798150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   187  100   187    0     0   1747      0 --:--:-- --:--:-- --:--:--  1747\n",
      "100 97.7M  100 97.7M    0     0  37.1M      0  0:00:02  0:00:02 --:--:-- 42.1M\n"
     ]
    }
   ],
   "source": [
    "!curl -L --create-dir https://github.com/onnx/models/raw/master/vision/classification/resnet/model/resnet50-caffe2-v1-9.onnx -o resnet/1/resnet50-caffe2-v1-9.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475d096b",
   "metadata": {},
   "source": [
    "Now, copy the ResNet model into MinIO bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ce59702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...v1-9.onnx:  97.74 MiB / 97.74 MiB ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 856.37 MiB/s 0s\u001b[0m\u001b[0m\u001b[m\u001b[32;1m"
     ]
    }
   ],
   "source": [
    "!./mc cp --recursive resnet minio/models/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deaf4ef",
   "metadata": {},
   "source": [
    "OpenVINO Model Server accepts the model in this particular folder structure, `models/<model_name>/<model-version>/<model>`.\n",
    "\n",
    "Let's make sure the model has been successfully copied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3162a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m\u001b[32m[2021-05-12 16:12:52 UTC]\u001b[0m\u001b[33m  98MiB\u001b[0m\u001b[1m resnet/1/resnet50-caffe2-v1-9.onnx\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!./mc ls -r minio/models/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76894faa",
   "metadata": {},
   "source": [
    "## Deploy OpenVINO Model Server\n",
    "\n",
    "Let's deploy an OpenVINO Model Server service in the cluster. We will create a serving of a single model, ResNet50 model in ONNX format, which we uploaded into MinIO bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903a3600",
   "metadata": {},
   "source": [
    "Here's the yaml file used to configure the OVMS service. We specified name to be `ovms-resnet` and `model_path` to be `s3://minio-service:9000/models/resnet`. Also, we defined `model_name` here. `\"CPU_THROUGHPUT_STREAMS\"` specifies number of CPU execution streams for the throughput mode. For more info, go to the [CPU Plugin's Supported Config Parameters](https://docs.openvinotoolkit.org/latest/openvino_docs_IE_DG_supported_plugins_CPU.html).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8ac8a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: intel.com/v1alpha1\n",
      "kind: Ovms\n",
      "metadata:\n",
      "  name: ovms-resnet\n",
      "spec:\n",
      "  aws_access_key_id: \"minio\"\n",
      "  aws_region: \"us-east-1\"\n",
      "  aws_secret_access_key: \"minio123\"\n",
      "  grpc_port: 8080\n",
      "  image_name: registry.connect.redhat.com/intel/openvino-model-server:latest\n",
      "  log_level: INFO\n",
      "  model_name: \"resnet\"\n",
      "  model_path: \"s3://minio-service:9000/models/resnet\"\n",
      "  plugin_config: '{\\\"CPU_THROUGHPUT_STREAMS\\\":\\\"1\\\"}'\n",
      "  replicas: 1\n",
      "  resources:\n",
      "    limits:\n",
      "      cpu: 4\n",
      "      memory: 2Gi\n",
      "  rest_port: 8081\n",
      "  service_type: ClusterIP\n"
     ]
    }
   ],
   "source": [
    "!cat ovms-resnet.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00a4ac1",
   "metadata": {},
   "source": [
    "Run the cell below to create new OVMS service called `ovms-resnet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d95ea1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ovms.intel.com/ovms-resnet created\n"
     ]
    }
   ],
   "source": [
    "!oc apply -f ovms-resnet.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9b265b",
   "metadata": {},
   "source": [
    "It should take around 15 seconds to create the pod and the service. They should start with `ovms-resnet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d89bbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                     READY     STATUS    RESTARTS   AGE\n",
      "minio-5c57f888dd-2mv2n   1/1       Running   0          14s\n",
      "NAME            TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE\n",
      "minio-service   ClusterIP   172.30.210.1   <none>        9000/TCP   14s\n"
     ]
    }
   ],
   "source": [
    "!oc get pod\n",
    "!oc get service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56db5d9a",
   "metadata": {},
   "source": [
    "Let's check if the OpenVINO Model Server service is running by making an API request via cURL. You will know it's working, if `state` is `AVAILABLE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfde5e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl: (6) Could not resolve host: ovms-resnet.ovms.svc\n"
     ]
    }
   ],
   "source": [
    "!curl http://ovms-resnet.ovms.svc:8081/v1/models/resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2e76b3",
   "metadata": {},
   "source": [
    "## Run a Prediction Request\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7264c146",
   "metadata": {},
   "source": [
    "We will run image classification on this image by making gRPC API requests to the `ovms-resnet` OVMS service.\n",
    "\n",
    "![image](bee.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32843899",
   "metadata": {},
   "source": [
    "Import Python packages needed to run prediction requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f7cba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "import numpy as np\n",
    "import classes\n",
    "from tensorflow import make_tensor_proto, make_ndarray, make_tensor_proto\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a366054",
   "metadata": {},
   "source": [
    "Next, we will create two functions to make a NumPy array from input image. The array will be transformed to required format and data range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "292fcd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img_data):\n",
    "    mean_vec = np.array([0.485, 0.456, 0.406])\n",
    "    stddev_vec = np.array([0.229, 0.224, 0.225])\n",
    "    norm_img_data = np.zeros(img_data.shape).astype('float32')\n",
    "    for i in range(img_data.shape[0]):\n",
    "         # for each pixel in each channel, divide the value by 255 to get value between [0, 1] and then normalize\n",
    "        norm_img_data[i,:,:] = (img_data[i,:,:]/255 - mean_vec[i]) / stddev_vec[i]\n",
    "    return norm_img_data\n",
    "\n",
    "def getJpeg(path, size):\n",
    "    with open(path, mode='rb') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    img = np.frombuffer(content, dtype=np.uint8)\n",
    "    img = cv2.imdecode(img, cv2.IMREAD_COLOR)  # BGR format\n",
    "    # format of data is HWC\n",
    "    # add image preprocessing if needed by the model\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = img.astype('float32')\n",
    "    #convert to NHWC\n",
    "    img = img.transpose(2,0,1)\n",
    "    # normalize to adjust to model training dataset\n",
    "    img = preprocess(img)\n",
    "    img = img.reshape(1,3,size,size)\n",
    "    print(path, img.shape, \"; data range:\",np.amin(img),\":\",np.amax(img))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52b4d53",
   "metadata": {},
   "source": [
    "Let's create a NumPy array from the bee image. Then, we will submit a gRPC request to the `ovms-resnet` service and print out the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c179daac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bee.jpeg (1, 3, 224, 224) ; data range: -2.117904 : 2.64\n",
      "Class with highest score: 309\n",
      "Detected class name: bee\n"
     ]
    }
   ],
   "source": [
    "img1 = getJpeg('bee.jpeg', 224)\n",
    "\n",
    "channel = grpc.insecure_channel(\"ovms-resnet.ovms.svc:8080\")\n",
    "stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "\n",
    "request = predict_pb2.PredictRequest()\n",
    "request.model_spec.name = \"resnet\"\n",
    "request.inputs[\"gpu_0/data_0\"].CopyFrom(make_tensor_proto(img1, shape=(img1.shape)))\n",
    "result = stub.Predict(request, 10.0) # result includes a dictionary with all model outputs\n",
    "\n",
    "output = make_ndarray(result.outputs[\"gpu_0/softmax_1\"])\n",
    "ma = np.argmax(output)\n",
    "print(\"Class with highest score: {}\".format(ma))\n",
    "print(\"Detected class name: {}\".format(classes.imagenet_classes[ma]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d6a363",
   "metadata": {},
   "source": [
    "## Run a Prediction Request on Your Image\n",
    "\n",
    "You can try it with your own image. In the first line of the next cell, change `<path-to-image>` to the path of the image on which you would like to run classification inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b786ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = getJpeg('<path-to-image>', 224)\n",
    "\n",
    "channel = grpc.insecure_channel(\"ovms-resnet.ovms.svc:8080\")\n",
    "stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "\n",
    "request = predict_pb2.PredictRequest()\n",
    "request.model_spec.name = \"resnet\"\n",
    "request.inputs[\"gpu_0/data_0\"].CopyFrom(make_tensor_proto(img1, shape=(img1.shape)))\n",
    "result = stub.Predict(request, 10.0) # result includes a dictionary with all model outputs\n",
    "\n",
    "output = make_ndarray(result.outputs[\"gpu_0/softmax_1\"])\n",
    "ma = np.argmax(output)\n",
    "print(\"Class with highest score: {}\".format(ma))\n",
    "print(\"Detected class name: {}\".format(classes.imagenet_classes[ma]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ec697d",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Let's free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acd6adc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ovms.intel.com \"ovms-resnet\" deleted\n",
      "deployment.apps \"minio\" deleted\n",
      "service \"minio-service\" deleted\n"
     ]
    }
   ],
   "source": [
    "!oc delete ovms ovms-resnet\n",
    "!oc delete deploy minio\n",
    "!oc delete service minio-service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d0528a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf resnet\n",
    "!rm mc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d64735",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In this notebook, you have learned how to deploy an OVMS service with ResNet50 image classification model in an OpenShift cluster. Next, you can explore other OpenShift OVMS notebooks:\n",
    "\n",
    "- [Send gRPC and API Calls via Python Scripts to OpenVINO Model Server in OpenShift](../402-model-serving-openshift-python-scripts/ovms-openshift-python-scripts.ipynb)\n",
    "- [Face Detection Multi Model OpenVINO Model Server Deployment in OpenShift](../403-model-serving-openshift-face-detection-dag/ovms-openshift-face-detection-dag.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
