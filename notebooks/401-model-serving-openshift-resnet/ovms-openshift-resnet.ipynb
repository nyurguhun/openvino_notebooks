{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "489f9607",
   "metadata": {},
   "source": [
    "# Deploy Image Classification with OpenVINO Model Server in OpenShift \n",
    "\n",
    "We will show you how to deploy OpenVINO Model Server (OVMS) in an OpenShift cluster and how to run a gRPC prediction request to the AI inference service.\n",
    "\n",
    "Requirements:\n",
    "- OpenShift cluster with the API access to a project\n",
    "- installed [OpenVINO Model Server Operator](https://catalog.redhat.com/software/operators/search?q=openvino)\n",
    "- JupyterLab environment with Python3 deployed in the cluster\n",
    "\n",
    "If you don't have an OpenShift account, you can sign up for 30 or 60 day [free trial of Red Hat OpenShift](https://www.openshift.com/try)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81a3ce6",
   "metadata": {},
   "source": [
    "## Login to OpenShift with API Token\n",
    "\n",
    "First, let's login to OpenShift cluster using `oc` tool. \n",
    "\n",
    "In the Red Hat OpenShift console, click on your username and select `Copy login command`.\n",
    "\n",
    "![copy-login.png](notebook-files/copy-login.png)\n",
    "\n",
    "Click on `Display Token` and your API token will appear.\n",
    "\n",
    "![log-in-with-token.png](notebook-files/log-in-with-token.png)\n",
    "\n",
    "Copy `Log in with token` command and paste it in the cell below. The command has your `<user-API-token>` and `<cluster-DNS-name>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415af260",
   "metadata": {},
   "outputs": [],
   "source": [
    "!oc login --token=<user-API-token> --server=https://api.<cluster-DNS-name>:6443"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb906425",
   "metadata": {},
   "source": [
    "Create `ovms` project and go to this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9df630",
   "metadata": {},
   "outputs": [],
   "source": [
    "!oc new-project ovms\n",
    "!oc project ovms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cffa22",
   "metadata": {},
   "source": [
    "## Create MinIO Storage\n",
    "\n",
    "OpenVINO Model Server exposes DL models over gRPC and REST interface. The models can be stored in cloud storage like AWS S3, Google Storage or Azure Blobs. In OpenShift and Kubernetes, Persistent Storage Claim could be used as well. In this tutorial, we will use MinIO service which is an equivalent of AWS S3.\n",
    "\n",
    "Let's create a MinIO service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab64dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!oc apply -f minio.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb5e90",
   "metadata": {},
   "source": [
    "Next step is to download `mc`, MinIO Client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9fd2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://dl.min.io/client/mc/release/linux-amd64/mc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d2dfcc",
   "metadata": {},
   "source": [
    "Change the access permissions on `mc`, so we can run commands with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4c4864",
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod 755 mc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08c1e76",
   "metadata": {},
   "source": [
    "Let's make an alias for the MinIO service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b9f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./mc alias set minio http://minio-service.ovms:9000 minio minio123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03492f3",
   "metadata": {},
   "source": [
    "Create a `minio/models` bucket; it's where we will store our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22118d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./mc mb minio/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ec5aea",
   "metadata": {},
   "source": [
    "## Create ResNet Model Repository\n",
    "\n",
    "Now, we will upload the models for serving in the OpenVINO Model Server. We will use [ResNet50 model in ONNX format](https://github.com/onnx/models/tree/master/vision/classification/resnet).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceede2fd",
   "metadata": {},
   "source": [
    "Copy the ResNet model from its repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af6ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L --create-dir https://github.com/onnx/models/raw/master/vision/classification/resnet/model/resnet50-caffe2-v1-9.onnx -o resnet/1/resnet50-caffe2-v1-9.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121d7bcb",
   "metadata": {},
   "source": [
    "Now, copy the ResNet model into MinIO bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33abef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./mc cp --recursive resnet minio/models/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781517ef",
   "metadata": {},
   "source": [
    "Let's make sure the model has been successfully copied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c74b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./mc ls -r minio/models/resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9427139",
   "metadata": {},
   "source": [
    "## Deploy OpenVINO Model Server\n",
    "\n",
    "Let's deploy an OpenVINO Model Server service in the cluster. We will create a serving of a single model, ResNet50 model in ONNX format, which we uploaded into MinIO bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ff19a",
   "metadata": {},
   "source": [
    "Here's the yaml file used to configure the OVMS service. We specified name to be `ovms-resnet` and `model_path` to be `s3://minio-service:9000/models/resnet`. Also, we defined `model_name` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ff641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ovms-resnet.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb14603a",
   "metadata": {},
   "source": [
    "Run the cell below to create new OVMS service called `ovms-resnet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce8c5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!oc apply -f ovms-resnet.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a49f8d",
   "metadata": {},
   "source": [
    "Let's see if pod and service were created. They should start with `ovms-resnet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c02539",
   "metadata": {},
   "outputs": [],
   "source": [
    "!oc get pod\n",
    "!oc get service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d177e58",
   "metadata": {},
   "source": [
    "Let's check if the OpenVINO Model Server service is running by making an API request via cURL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b228853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://ovms-resnet.ovms.svc:8081/v1/models/resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b41668",
   "metadata": {},
   "source": [
    "## Run a Prediction Request\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dca1a22",
   "metadata": {},
   "source": [
    "We will run image classification on this image by making gRPC API requests to the `ovms-resnet` OVMS service.\n",
    "\n",
    "![image](bee.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc23d22",
   "metadata": {},
   "source": [
    "Import Python packages needed to run prediction requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47906ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "import numpy as np\n",
    "import classes\n",
    "from tensorflow import make_tensor_proto, make_ndarray, make_tensor_proto\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eebcfb",
   "metadata": {},
   "source": [
    "Next, we will create two functions to make a NumPy array from input image. The array will be transformed to required format and data range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b62bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img_data):\n",
    "    mean_vec = np.array([0.485, 0.456, 0.406])\n",
    "    stddev_vec = np.array([0.229, 0.224, 0.225])\n",
    "    norm_img_data = np.zeros(img_data.shape).astype('float32')\n",
    "    for i in range(img_data.shape[0]):\n",
    "         # for each pixel in each channel, divide the value by 255 to get value between [0, 1] and then normalize\n",
    "        norm_img_data[i,:,:] = (img_data[i,:,:]/255 - mean_vec[i]) / stddev_vec[i]\n",
    "    return norm_img_data\n",
    "\n",
    "def getJpeg(path, size):\n",
    "    with open(path, mode='rb') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    img = np.frombuffer(content, dtype=np.uint8)\n",
    "    img = cv2.imdecode(img, cv2.IMREAD_COLOR)  # BGR format\n",
    "    # format of data is HWC\n",
    "    # add image preprocessing if needed by the model\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = img.astype('float32')\n",
    "    #convert to NHWC\n",
    "    img = img.transpose(2,0,1)\n",
    "    # normalize to adjust to model training dataset\n",
    "    img = preprocess(img)\n",
    "    img = img.reshape(1,3,size,size)\n",
    "    print(path, img.shape, \"; data range:\",np.amin(img),\":\",np.amax(img))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e530d7a",
   "metadata": {},
   "source": [
    "Let's create a NumPy array from the bee image. Then, we will submit a gRPC request to the `ovms-resnet` service and print out the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb122f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = getJpeg('bee.jpeg', 224)\n",
    "\n",
    "channel = grpc.insecure_channel(\"ovms-resnet.ovms.svc:8080\")\n",
    "stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "\n",
    "request = predict_pb2.PredictRequest()\n",
    "request.model_spec.name = \"resnet\"\n",
    "request.inputs[\"gpu_0/data_0\"].CopyFrom(make_tensor_proto(img1, shape=(img1.shape)))\n",
    "result = stub.Predict(request, 10.0) # result includes a dictionary with all model outputs\n",
    "\n",
    "output = make_ndarray(result.outputs[\"gpu_0/softmax_1\"])\n",
    "ma = np.argmax(output)\n",
    "print(\"Class with highest score: {}\".format(ma))\n",
    "print(\"Detected class name: {}\".format(classes.imagenet_classes[ma]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd02133",
   "metadata": {},
   "source": [
    "## Run a Prediction Request on Your Image\n",
    "\n",
    "You can try it with your own image. In the first line of the next cell, change `<path-to-image>` to the path of the image on which you would like to run classification inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465288f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = getJpeg('<path-to-image>', 224)\n",
    "\n",
    "channel = grpc.insecure_channel(\"ovms-resnet.ovms.svc:8080\")\n",
    "stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "\n",
    "request = predict_pb2.PredictRequest()\n",
    "request.model_spec.name = \"resnet\"\n",
    "request.inputs[\"gpu_0/data_0\"].CopyFrom(make_tensor_proto(img1, shape=(img1.shape)))\n",
    "result = stub.Predict(request, 10.0) # result includes a dictionary with all model outputs\n",
    "\n",
    "output = make_ndarray(result.outputs[\"gpu_0/softmax_1\"])\n",
    "ma = np.argmax(output)\n",
    "print(\"Class with highest score: {}\".format(ma))\n",
    "print(\"Detected class name: {}\".format(classes.imagenet_classes[ma]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15248f2c",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Let's free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b42cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!oc delete ovms ovms-resnet\n",
    "!oc delete deploy minio\n",
    "!oc delete service minio-service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264e7eb7",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In this notebook, you have learned how to deploy an OVMS service with ResNet50 image classification model in an OpenShift cluster. Next, you can explore other OpenShift OVMS notebooks:\n",
    "\n",
    "- [Deploy Image Classification with OpenVINO Model Server in OpenShift](../401-model-serving-openshift-resnet/ovms-openshift-resnet.ipynb)\n",
    "- [Face Detection Multi Model OpenVINO Model Server Deployment in OpenShift](../403-model-serving-openshift-face-detection-dag/ovms-openshift-face-detection-dag.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
